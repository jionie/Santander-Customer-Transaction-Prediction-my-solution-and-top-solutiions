{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc='Progress')\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 202) (200000, 201)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_p_n(df, drop_list):\n",
    "    \n",
    "    df_ = df.drop(drop_list, axis=1)\n",
    "    df_list = df_.values\n",
    "\n",
    "    positives = np.zeros(train.shape[0])\n",
    "    negatives = np.zeros(train.shape[0])\n",
    "\n",
    "    for i in range(df_list.shape[0]):\n",
    "        positive = np.where(df_list[i]>0,df_list[i], 0)\n",
    "        negative = np.where(df_list[i]<0, df_list[i], 0)\n",
    "        positives[i] = len(set(positive))-1\n",
    "        negatives[i] = len(set(negative))-1\n",
    "\n",
    "    df['positive'] = positives\n",
    "    df['negative'] = negatives\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = add_p_n(df_train, ['ID_code', 'target'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = add_p_n(df_test, ['ID_code'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_lb = pd.read_csv(\"../input/Private_LB.csv\")\n",
    "public_lb = pd.read_csv(\"../input/Public_LB.csv\")\n",
    "synthetic = pd.read_csv(\"../input/synthetic_samples_indexes.csv\")\n",
    "\n",
    "private_lb = private_lb.rename(index=str, columns={\"Private_LB\": \"index\"})\n",
    "public_lb = public_lb.rename(index=str, columns={\"Public_LB\": \"index\"})\n",
    "synthetic = synthetic.rename(index=str, columns={\"synthetic_samples_indexes\": \"index\"})\n",
    "\n",
    "true = public_lb.append(private_lb, ignore_index=True)\n",
    "test_true = df_test.iloc[true[\"index\"], :]\n",
    "test_synthetic = df_test.iloc[synthetic[\"index\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true['target'] = np.ones(test_true.shape[0])\n",
    "test_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['target']\n",
    "\n",
    "train0 = df_train[y_train.values==0].copy()\n",
    "train1 = df_train[y_train.values==1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta = np.zeros((6, 200))\n",
    "for i in range(200):\n",
    "    sta[0, i] = np.std(df_train['var_'+str(i)])\n",
    "    sta[1, i] = np.mean(df_train['var_'+str(i)])\n",
    "    sta[2, i] = np.std(train0['var_'+str(i)])\n",
    "    sta[3, i] = np.mean(train0['var_'+str(i)])\n",
    "    sta[4, i] = np.std(train1['var_'+str(i)])\n",
    "    sta[5, i] = np.mean(train1['var_'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic = pd.DataFrame(sta, columns=['var_'+str(i) for i in range(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic['item'] = ['std_all', 'mean_all', 'std_0', 'mean_0', 'std_1', 'mean_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic = statistic.set_index('item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic.to_csv('../input/statistics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistic[['var_150', 'var_153', 'var_158']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 200\n",
    "\n",
    "def ecdf(s):\n",
    "    \"\"\" An ECDF computation function using pandas methods.\"\"\"\n",
    "    value_counts_s = s.value_counts()\n",
    "    return value_counts_s.sort_index().cumsum().div(len(s))\n",
    "\n",
    "def optimal_fd_bins(s):\n",
    "    \"\"\" \n",
    "    Optimal number of bins using the FD rule of thumb: \n",
    "    https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule\n",
    "    \"\"\"\n",
    "    # Computeing the interquartile range: \n",
    "    # https://en.wikipedia.org/wiki/Interquartile_range\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    width = 2 * iqr / (len(s) ** 0.33)\n",
    "    return int((s.max() - s.min()) / width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_FEATURES):\n",
    "    col = 'var_' + str(i)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # ECDF\n",
    "    ecdf(df_train.loc[lambda df: df.target == 0, col]).plot(ax=ax[0], label=\"0\")\n",
    "    ecdf(df_train.loc[lambda df: df.target == 1, col]).plot(ax=ax[0], label=\"1\")\n",
    "    ax[0].set_title(f\"ECDF for {col}\")\n",
    "    ax[0].legend()\n",
    "    \n",
    "    # Histogram\n",
    "    bins = optimal_fd_bins(df_train[col])\n",
    "    df_train.loc[lambda df: df.target == 0, col].plot(kind=\"hist\", bins=bins, ax=ax[1], \n",
    "                                                      label=\"0\")\n",
    "    df_train.loc[lambda df: df.target == 1, col].plot(kind=\"hist\", bins=bins, ax=ax[1], \n",
    "                                                      label=\"1\")\n",
    "    ax[1].set_title(f\"Freedmanâ€“Diaconis histogram for {col}\")\n",
    "    ax[1].legend()      \n",
    "    \n",
    "    plt.show()\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique(train_df):\n",
    "\n",
    "    for var in ['var_{}'.format(x) for x in range(0, 200)]:\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "        train_df.groupby(var)['target'].agg(['count','mean']).sort_values('count') \\\n",
    "            .plot(kind='scatter', x='mean', y='count', ax=ax1, alpha=0.1, title='Train Data')\n",
    "        train_df['random_{}'.format(var)] = np.random.normal(train_df[var].mean(), train_df[var].std(), train_df.shape[0]).round(4)\n",
    "        train_df.groupby('random_{}'.format(var))['target'].agg(['count','mean']).sort_values('count') \\\n",
    "            .plot(kind='scatter', x='mean', y='count', ax=ax2, alpha=0.1, title='Simulated Data')\n",
    "        # Both together\n",
    "        train_df.groupby(var)['target'].agg(['count','mean']).sort_values('count') \\\n",
    "            .plot(kind='scatter', x='mean', y='count', ax=ax3, alpha=0.1)\n",
    "        train_df.groupby('random_{}'.format(var))['target'].agg(['count','mean']).sort_values('count') \\\n",
    "            .plot(kind='scatter', x='mean', y='count', ax=ax3, alpha=0.1, color='orange', title='Both')\n",
    "        ax1.set_xlabel('average target')\n",
    "        ax2.set_xlabel('average target')\n",
    "        ax3.set_xlabel('average target')\n",
    "        ax1.set_ylabel('count of unique value')\n",
    "        ax2.set_ylabel('count of unique value')\n",
    "        ax3.set_ylabel('count of unique value')\n",
    "        fig.suptitle(var)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique(train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_wired = [12, 108, 126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_feature(train_df, var):\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "    train_df.groupby(var)['target'].agg(['count','mean']).sort_values('count') \\\n",
    "        .plot(kind='scatter', x='mean', y='count', ax=ax1, alpha=0.1, title='Train Data')\n",
    "    train_df['random_{}'.format(var)] = np.random.normal(train_df[var].mean(), train_df[var].std(), train_df.shape[0]).round(4)\n",
    "    train_df.groupby('random_{}'.format(var))['target'].agg(['count','mean']).sort_values('count') \\\n",
    "        .plot(kind='scatter', x='mean', y='count', ax=ax2, alpha=0.1, title='Simulated Data')\n",
    "    # Both together\n",
    "    train_df.groupby(var)['target'].agg(['count','mean']).sort_values('count') \\\n",
    "        .plot(kind='scatter', x='mean', y='count', ax=ax3, alpha=0.1)\n",
    "    train_df.groupby('random_{}'.format(var))['target'].agg(['count','mean']).sort_values('count') \\\n",
    "        .plot(kind='scatter', x='mean', y='count', ax=ax3, alpha=0.1, color='orange', title='Both')\n",
    "    ax1.set_xlabel('average target')\n",
    "    ax2.set_xlabel('average target')\n",
    "    ax3.set_xlabel('average target')\n",
    "    ax1.set_ylabel('count of unique value')\n",
    "    ax2.set_ylabel('count of unique value')\n",
    "    ax3.set_ylabel('count of unique value')\n",
    "    fig.suptitle(var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_train['var_12'].mean()\n",
    "std = df_train['var_12'].std()\n",
    "df_train['var_12'] = df_train['var_12'].apply(lambda x:(x-mean)/std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_feature(df_train, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_feature(test_true, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_12 = np.max(df_train['var_12'])\n",
    "max_gaussian_12 = np.max(np.random.normal(df_train['var_12'].mean(), \\\n",
    "                                          df_train['var_12'].std(), df_train.shape[0]).round(4))\n",
    "\n",
    "print(max_12)\n",
    "print(max_gaussian_12)\n",
    "\n",
    "min_12 = np.min(df_train['var_12'])\n",
    "min_gaussian_12 = np.min(np.random.normal(df_train['var_12'].mean(), \\\n",
    "                                          df_train['var_12'].std(), df_train.shape[0]).round(4))\n",
    "\n",
    "print(min_12)\n",
    "print(min_gaussian_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistic['var_12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df_train['var_12']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(np.random.normal(df_train['var_12'].mean(), \\\n",
    "                                          df_train['var_12'].std(), df_train.shape[0]).round(4)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_train.groupby(['var_12'])['target'].agg(['count','mean']).sort_values('count', ascending=False)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test = test_true.groupby(['var_12'])['target'].agg(['count','mean']).sort_values('count', ascending=False)\n",
    "print(new_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gauss = df_train.groupby(['random_var_12'])['target'].agg(['count','mean']).sort_values('count', ascending=False)\n",
    "print(new_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gauss_test = test_true.groupby(['random_var_12'])['target'].agg(['count','mean']).sort_values('count', ascending=False)\n",
    "print(new_gauss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gauss = new_gauss.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_gauss[new_gauss['random_var_12']==13.5540])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.reset_index()\n",
    "print(new_df[new_df['var_12']==13.5540])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_feature(df_train, 'var_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_train.groupby(['var_0'])['target'].agg(['count','mean']).sort_values('count', ascending=False)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gauss = df_train.groupby(['random_var_0'])['target'].agg(['count','mean']).sort_values('count', ascending=False)\n",
    "print(new_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_feature(df_train, 'var_108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_feature(df_train, 'var_126')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['new'] = df_train['var_102'] + df_train['var_10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Wierd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(statistic[['var_12', 'var_108', 'var_126']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dis(name):\n",
    "    #xx = plt.xlim()\n",
    "    sns.distplot(train0[name], label = 't=0')\n",
    "    sns.distplot(train1[name], label = 't=1')\n",
    "    plt.title(name)\n",
    "    plt.legend()\n",
    "    #plt.xlim(xx)\n",
    "    plt.xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis('var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_new(df_train, new_train0, new_train1, name):\n",
    "    xx = plt.xlim()\n",
    "    s_new = [0]\n",
    "    m_new = [0]\n",
    "\n",
    "    # CALCULATE MEANS AND STANDARD DEVIATIONS\n",
    "    s_new[0] = np.std(df_train[name])\n",
    "    m_new[0] = np.mean(df_train[name])\n",
    "\n",
    "    # CALCULATE PROB(TARGET=1 | X)\n",
    "    def getp_new(name, x):\n",
    "        c = 3 #smoothing factor\n",
    "        a = len( new_train1[ (new_train1[name]>x-s_new[0]/c)&(new_train1[name]<x+s_new[0]/c) ] ) \n",
    "        b = len( new_train0[ (new_train0[name]>x-s_new[0]/c)&(new_train0[name]<x+s_new[0]/c) ] )\n",
    "        if a+b<500: return 0.1 #smoothing factor\n",
    "        # RETURN PROBABILITY\n",
    "        return a / (a+b)\n",
    "        # ALTERNATIVELY RETURN ODDS\n",
    "        # return a / b\n",
    "\n",
    "    # SMOOTH A DISCRETE FUNCTION\n",
    "    def smooth(x,st=1):\n",
    "        for j in range(st):\n",
    "            x2 = np.ones(len(x)) * 0.1\n",
    "            for i in range(len(x)-2):\n",
    "                x2[i+1] = 0.25*x[i]+0.5*x[i+1]+0.25*x[i+2]\n",
    "            x = x2.copy()\n",
    "        return x\n",
    "\n",
    "    rmin_new=-5; rmax_new=5; \n",
    "    # CALCULATE PROBABILITIES FOR 501 BINS\n",
    "    res_new=501\n",
    "\n",
    "    pr_new = 0.1 * np.ones(res_new)\n",
    "    pr2_new = pr_new.copy()\n",
    "    xr_new = np.zeros(res_new)\n",
    "    xr2_new = xr_new.copy()\n",
    "    ct2_new = 0\n",
    "\n",
    "    ct_new = 0\n",
    "    # CALCULATE PROBABILITY FUNCTION FOR VAR\n",
    "    for i in np.linspace(rmin_new,rmax_new,res_new):\n",
    "        pr_new[ct_new] = getp_new(name, m_new[0]+i*s_new[0])\n",
    "        xr_new[ct_new] = m_new[0]+i*s_new[0]\n",
    "        xr2_new[ct_new] = i\n",
    "        ct_new += 1\n",
    "\n",
    "    # SMOOTH FUNCTION FOR PRETTIER DISPLAY\n",
    "    # BUT USE UNSMOOTHED FUNCTION FOR PREDICTION\n",
    "    pr2_new[:] = smooth(pr_new[:],res_new//10)\n",
    "\n",
    "    # DISPLAY PROBABILITY FUNCTION\n",
    "    plt.plot(xr_new[:],pr2_new[:],'-')\n",
    "    plt.title('P( t=1 | ' + name + ' )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_new(df_train, train0, train1, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_new(df_train, train0, train1, 'var_75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis('var_108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis('var_126')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, var='var_12'):\n",
    "    df['random_{}'.format(var)] = np.random.normal(df[var].mean(), df[var].std(), 200000).round(4)\n",
    "    var_counts = pd.DataFrame(df.groupby(var)['ID_code'].count()).reset_index()\n",
    "    var_counts_random = pd.DataFrame(df.groupby('random_{}'.format(var))['ID_code'].count()).reset_index()\n",
    "    merged_counts = pd.merge(var_counts, var_counts_random, left_on=var, right_on='random_{}'.format(var))\n",
    "    merged_counts['diff'] = merged_counts['ID_code_x'] - merged_counts['ID_code_y']\n",
    "    df['{}_diff_normal_dist'.format(var)] = df.merge(merged_counts[[var,'diff']], how='left')['diff']\n",
    "    df = df.drop('random_{}'.format(var), axis=1)\n",
    "    return df\n",
    "\n",
    "# Loop and add features\n",
    "for var in tqdm(['var_{}'.format(x) for x in range(0, 200)]):\n",
    "    train_df = transform(train_df, var=var)\n",
    "    test_df = transform(test_df, var=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y,yp):\n",
    "    yp = np.clip(yp,1e-5,1-1e-5)\n",
    "    return -y*np.log(yp)-(1-y)*np.log(1-yp)\n",
    "    \n",
    "def reverse(tr):\n",
    "    reverse_list = [0,1,2,3,4,5,6,7,8,11,15,16,18,19,\n",
    "                22,24,25,26,27,41,29,\n",
    "                32,35,37,40,48,49,47,\n",
    "                55,51,52,53,60,61,62,103,65,66,67,69,\n",
    "                70,71,74,78,79,\n",
    "                82,84,89,90,91,94,95,96,97,99,\n",
    "                105,106,110,111,112,118,119,125,128,\n",
    "                130,133,134,135,137,138,\n",
    "                140,144,145,147,151,155,157,159,\n",
    "                161,162,163,164,167,168,\n",
    "                170,171,173,175,176,179,\n",
    "                180,181,184,185,187,189,\n",
    "                190,191,195,196,199]\n",
    "    reverse_list = ['var_%d'%i for i in reverse_list]\n",
    "    for col in reverse_list:\n",
    "        tr[col] = tr[col]*(-1)\n",
    "        \n",
    "    return tr\n",
    "\n",
    "def scale(tr):\n",
    "    for col in tr.columns:\n",
    "        if col.startswith('var_'):\n",
    "            mean,std = tr[col].mean(),tr[col].std()\n",
    "            tr[col] = (tr[col]-mean)/std\n",
    "    return tr\n",
    "\n",
    "def getp_vec_sum(x,x_sort,y,std,c=0.5):\n",
    "    # x is sorted\n",
    "    left = x - std/c\n",
    "    right = x + std/c\n",
    "    p_left = np.searchsorted(x_sort,left)\n",
    "    p_right = np.searchsorted(x_sort,right)\n",
    "    p_right[p_right>=y.shape[0]] = y.shape[0]-1\n",
    "    p_left[p_left>=y.shape[0]] = y.shape[0]-1\n",
    "    return (y[p_right]-y[p_left])\n",
    "\n",
    "def get_pdf(tr,col,x_query=None,smooth=3):\n",
    "    xx = plt.xlim()\n",
    "    std = tr[col].std()\n",
    "    df = tr.groupby(col).agg({'target':['sum','count']})\n",
    "    cols = ['sum_y','count_y']\n",
    "    df.columns = cols\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values(col)\n",
    "    y,c = cols\n",
    "    \n",
    "    df[y] = df[y].cumsum()\n",
    "    df[c] = df[c].cumsum()\n",
    "    \n",
    "    if x_query is None:\n",
    "        rmin,rmax,res = -5.0, 5.0, 501\n",
    "        x_query = np.linspace(rmin,rmax,res)\n",
    "    \n",
    "    dg = pd.DataFrame()\n",
    "    tm = getp_vec_sum(x_query,df[col].values,df[y].values,std,c=smooth)\n",
    "    cm = getp_vec_sum(x_query,df[col].values,df[c].values,std,c=smooth)+1\n",
    "    dg['res'] = tm/cm\n",
    "    dg.loc[cm<500,'res'] = 0.1\n",
    "    return dg['res'].values\n",
    "\n",
    "def get_pdfs(tr):\n",
    "    y = []\n",
    "    for i in range(200):\n",
    "        name = 'var_%d'%i\n",
    "        res = get_pdf(tr,name)\n",
    "        y.append(res)\n",
    "    return np.vstack(y)\n",
    "\n",
    "def print_corr(corr_mat,col,bar=0.97):\n",
    "    print(col)\n",
    "    cols = corr_mat.loc[corr_mat[col]>bar,col].index.values\n",
    "    cols_ = ['var_%s'%(i.split('_')[-1]) for i in cols]\n",
    "    print(cols)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_12\n",
      "var_108\n",
      "var_126\n"
     ]
    }
   ],
   "source": [
    "def processing_new(df, cols, df_add):\n",
    "    \n",
    "    total_cols = cols.copy()\n",
    "    total_cols.append('ID_code')\n",
    "    tmp = pd.concat([df[total_cols], df_add[total_cols]], axis=0)\n",
    "    for feature in cols:\n",
    "        print(feature)\n",
    "       \n",
    "        #df[feature] = df[feature].round(4)\n",
    "        count_max = tmp[feature].value_counts().index[0]\n",
    "        tmp[feature+'_map'] = tmp.groupby([feature])['ID_code'].transform('count')\n",
    "        size = tmp.shape[0]\n",
    "        tmp[feature+'_map'] = tmp[feature+'_map'].apply(lambda x: size/x)\n",
    "        tmp[feature+'_map'] = tmp[feature+'_map']/(np.abs(tmp[feature] - count_max)+1e-8)\n",
    "        #tmp[feature+'_map'] = tmp[feature+'_map'].apply(lambda x: 0 if x>2 else x)\n",
    "        df[feature+'_map'] = tmp.iloc[:df.shape[0]][feature+'_map']\n",
    "         \n",
    "    return df\n",
    "\n",
    "def processing_new_new(df, cols, df_add):\n",
    "    \n",
    "    def trans(x, m, w):\n",
    "        if(x in w.index):\n",
    "            return w[x]\n",
    "        else:\n",
    "            return m[x]\n",
    "    \n",
    "    for feature in cols:\n",
    "        print(feature)\n",
    "        \n",
    "        df_add_count = df_add[feature].value_counts()/df_add.shape[0]\n",
    "        df_count = df[feature].value_counts()/df.shape[0]\n",
    "        \n",
    "        #df[feature+'_map'] = df.groupby([feature])['ID_code'].transform('count')\n",
    "        #size = tmp.shape[0]\n",
    "        #df[feature+'_map'] /= size\n",
    "        #df[feature+'_map'] = (df[feature] + np.random.normal(1e-15, 1e-15, df.shape[0])).round(16)\n",
    "        \n",
    "        #df[feature+'_map'] = df[feature+'_map']-df[feature+'_map_test']\n",
    "        \n",
    "        #df = df.drop([feature+'_map_test'], axis=1)\n",
    "         \n",
    "    return df\n",
    "\n",
    "#train_new = scale(train_new)\n",
    "train_new = processing_new_new(train_new, ['var_12', 'var_108', 'var_126'], test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(df, feature):\n",
    "    negData = df.loc[df['target'] == 0][feature]\n",
    "    posData = df.loc[df['target'] == 1][feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData, posData], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_train_test_fre(train_new, test_true, feature):\n",
    "    \n",
    "    tmp1 = train_new[feature].value_counts()\n",
    "    tmp2 = test_true[feature].value_counts()\n",
    "    negData = train_new[feature].apply(lambda x:tmp1.loc[x]/train_new.shape[0])\n",
    "    posData = test_true[feature].apply(lambda x:tmp2.loc[x]/test_true.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData*10000, posData*10000], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_train_fre(train_new, feature):\n",
    "    \n",
    "    a = train_new.loc[train_new['target']==1][feature]\n",
    "    b = train_new.loc[train_new['target']==0][feature]\n",
    "    \n",
    "    tmp1 = a.value_counts()\n",
    "    tmp2 = b.value_counts()\n",
    "    negData = a.apply(lambda x:tmp1.loc[x]/train_new.shape[0])\n",
    "    posData = b.apply(lambda x:tmp2.loc[x]/train_new.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData*10000, posData*10000], \n",
    "                                  bins=40, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_ratio(train_new, feature):\n",
    "    \n",
    "    a = train_new.loc[train_new['target']==1][feature]\n",
    "    b = train_new.loc[train_new['target']==0][feature]\n",
    "    \n",
    "    tmp1 = a.value_counts()\n",
    "    tmp2 = b.value_counts()\n",
    "    \n",
    "    def ratio(x, tmp1, tmp2):\n",
    "        if(x not in tmp2.index):\n",
    "            return 1\n",
    "        else:\n",
    "            return tmp1.loc[x]/tmp2.loc[x]\n",
    "    \n",
    "    Data = a.apply(lambda x:ratio(x, tmp1, tmp2))\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([Data], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_ratio(train_new, 'var_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_train_fre(train_new, 'var_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_train_test_fre(train_new, test_true, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = train_new.corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n",
    "corrs = corrs[corrs['level_0'] < corrs['level_1']]\n",
    "corrs.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_new['target']\n",
    "\n",
    "train0 = train_new[y_train.values==0].copy()\n",
    "train1 = train_new[y_train.values==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['var_' + str(i) for i in range(200)]\n",
    "count = []\n",
    "index = 13\n",
    "for col in c:\n",
    "    if train_new[col].value_counts()[train_new.iloc[index][col]]==1:\n",
    "        count.append(col)\n",
    "print(count, train_new.iloc[index]['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in train1_count.index:\n",
    "    if i not in train0_count.index:\n",
    "        arr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14.779000000000002 - 14.7790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in arr:\n",
    "    if i not in test_.index:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train0_count.index:\n",
    "    if i not in train1_count.index:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = test_true['var_12'].value_counts()\n",
    "print(test_/test_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_count = train1['var_12'].value_counts()\n",
    "print(train1_count/train_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0_count = train0['var_12'].value_counts()\n",
    "print(train0_count/train_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_all(df, test, test_synthetic, feature):\n",
    "    negData = df.loc[df['target'] == 0][feature]\n",
    "    posData = df.loc[df['target'] == 1][feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([df[feature], test[feature], test_synthetic[feature], negData, posData], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"train\", \"test_true\",  \"test_synthetic\", \"target 0\", \"target 1\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_train_test(train_new, test_true, test_synthetic, feature):\n",
    "    negData = train_new[feature]\n",
    "    posData = test_true[feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData, posData, test_synthetic[feature]], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"train\", \"test_true\", \"test_synthetic\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_test(test_true, test_synthetic, feature):\n",
    " \n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([test_true[feature], test_synthetic[feature]], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"test_true\", \"test_synthetic\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_test_all(train, test, feature):\n",
    " \n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([train[feature], test[feature]], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"train\", \"test\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_train_test_true(train_new, test_true, feature):\n",
    "    negData = train_new[feature]\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData, test_true[feature]], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"train\", \"test_true\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_train_test_syn(train_new, test_synthetic, feature):\n",
    "    negData = train_new[feature]\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData, test_synthetic[feature]], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"train\", \"test_synthetic\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(df, feature):\n",
    "        \n",
    "    bin_ = 1000\n",
    "    hist_random, bin_edges_random = np.histogram(df[feature], bins=bin_, density=True)\n",
    "    \n",
    "    def get_gradient(x, hist_random, bin_edges_random):\n",
    "        \n",
    "        if((np.searchsorted(bin_edges_random,x)-1!=0)and(np.searchsorted(bin_edges_random,x)-1!=bin_-1)):\n",
    "            \n",
    "            t_2 = hist_random[np.searchsorted(bin_edges_random,x)]\n",
    "            t_1 = hist_random[np.searchsorted(bin_edges_random,x)-1]\n",
    "            t_0 = hist_random[np.searchsorted(bin_edges_random,x)-2]\n",
    "            \n",
    "            if(t_1-t_0==0):\n",
    "                if(t_2-t_1==0):\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 100\n",
    "            \n",
    "            return (t_2-t_1)/(t_1-t_0)\n",
    "        \n",
    "        if(np.searchsorted(bin_edges_random,x)-1==0): \n",
    "            return 100\n",
    "            \n",
    "        if(np.searchsorted(bin_edges_random,x)-1==bin_-1):\n",
    "            return -100\n",
    "            \n",
    "    df['gradient_'+feature] = df[feature].apply(lambda x: get_gradient(x, hist_random, bin_edges_random))\n",
    "                                                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = get_gradient(train_new, 'var_13')\n",
    "train_new = get_gradient(train_new, 'random_var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new['gradient_var_13'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_target(df, feature):\n",
    "    negData = df.loc[df['target'] == 0][feature]\n",
    "    posData = df.loc[df['target'] == 1][feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData, posData], \n",
    "                                  bins=100, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"target 0\", \"target 1\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'gradient_var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'gradient_random_var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis_hist(train_new, 'gradient_var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis_hist(train_new, 'gradient_random_var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dis_hist(df, var):\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(var)\n",
    "    outs1, outs2, outs3 = ax.hist([df[var]], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(var),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_test(test_true, test_synthetic, 'var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_target_true(df, test, feature):\n",
    "    negData = df.loc[df['target'] == 0][feature]\n",
    "    posData = df.loc[df['target'] == 1][feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([test[feature], negData, posData], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"test_true\", \"target 0\", \"target 1\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_target_synthetic(df, test_synthetic, feature):\n",
    "    negData = df.loc[df['target'] == 0][feature]\n",
    "    posData = df.loc[df['target'] == 1][feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([test_synthetic[feature], negData, posData], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"test_synthetic\", \"target 0\", \"target 1\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_train_test_syn(train_new, test_synthetic, 'var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_train_test_true(train_new, test_true, 'var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_test_all(df_train, df_test, 'var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_diff(train_new, feature):\n",
    "    \n",
    "    train_new['random_'+feature] = np.random.normal(train_new[feature].mean(), \\\n",
    "                                                  train_new[feature].std(), train_new.shape[0]).round(4)\n",
    "\n",
    "    negData = train_new[feature]\n",
    "    posData = train_new['random_'+feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData, posData, df_test[feature]], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(feature, \"random_\"+feature, \"test\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_diff(train_new, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_all(train_new, test_true, test_synthetic, 'var_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'var_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_train_test(train_new, test_true, test_synthetic, 'var_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target_true(train_new, test_true, 'var_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target_synthetic(train_new, test_synthetic, 'var_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target_test(train_new, df_test, 'var_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, add_0, add_1, var):\n",
    "    \n",
    "    total_cols = [var]\n",
    "    total_cols.append('ID_code')\n",
    "    tmp = pd.concat([df[total_cols], add_0[total_cols], add_1[total_cols]], axis=0)\n",
    "    \n",
    "    tmp['random_{}'.format(var)] = np.random.normal(tmp[var].mean(), tmp[var].std(), tmp.shape[0]).round(4)\n",
    "    var_counts = pd.DataFrame(tmp.groupby(var)['ID_code'].count()).reset_index()\n",
    "    var_counts_random = pd.DataFrame(tmp.groupby('random_{}'.format(var))['ID_code'].count()).reset_index()\n",
    "    merged_counts = pd.merge(var_counts, var_counts_random, left_on=var, right_on='random_{}'.format(var))\n",
    "    merged_counts['diff'] = merged_counts['ID_code_x'] - merged_counts['ID_code_y']\n",
    "    tmp['{}_diff_normal_dist'.format(var)] = tmp.merge(merged_counts[[var,'diff']], how='left')['diff']\n",
    "    df['{}_diff_normal_dist'.format(var)] = tmp.iloc[:df.shape[0]]['{}_diff_normal_dist'.format(var)]\n",
    "    #df = df.drop('random_{}'.format(var), axis=1)\n",
    "    return df\n",
    "\n",
    "train_new = transform(train_new, test_true, test_synthetic, 'var_12')\n",
    "test_true = transform(test_true, train_new, test_synthetic, 'var_12')\n",
    "test_synthetic = transform(test_synthetic, train_new, test_true, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fre(df, add_0, add_1, var):\n",
    "    \n",
    "    tmp = pd.concat([df[var], add_0[var], add_1[var]], axis=0)\n",
    "    size = tmp.shape[0]\n",
    "    df['test_'+var] = df[var].map(dict(df[var].value_counts()/size))\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_new = transform_fre(train_new, test_true, test_synthetic, 'var_12')\n",
    "test_true = transform_fre(test_true, train_new, test_synthetic, 'var_12')\n",
    "test_synthetic = transform_fre(test_synthetic, train_new, test_true, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = ['var_12']\n",
    "tmp = pd.DataFrame(train_new.groupby(important)['target'].mean()).sort_values(by='target', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['count'] = np.zeros(tmp.shape[0])\n",
    "\n",
    "for feature in important:\n",
    "    \n",
    "    tmp['count'] += tmp[feature].map(dict(tmp[feature].value_counts()/tmp.shape[0]))\n",
    "\n",
    "tmp = tmp.sort_values(by='count', ascending=False)\n",
    "    \n",
    "print(tmp.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = ['var_' + str(i) for i in range(200)]\n",
    "train_new['count'] = np.zeros(train_new.shape[0])\n",
    "size = train_new.shape[0]\n",
    "for feature in important:\n",
    "    \n",
    "    train_new[feature+'_count'] = train_new.groupby([feature])['ID_code'].transform('count')/size\n",
    "    train_new['count'] += train_new[feature+'_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in important:\n",
    "    \n",
    "    train_new[feature+'_count'] -= train_new['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fre_dis(df, add_0, add_1, cols):\n",
    "    \n",
    "    total_cols = cols.copy()\n",
    "    total_cols.append('ID_code')\n",
    "    tmp = pd.concat([df[total_cols], add_0[total_cols], add_1[total_cols]], axis=0)\n",
    "    print(tmp.shape)\n",
    "    tmp['count'] = np.zeros(tmp.shape[0])\n",
    "    size = tmp.shape[0]\n",
    "    \n",
    "    for var in cols:\n",
    "        \n",
    "        print(var)\n",
    "    \n",
    "        tmp[var+'_count'] = tmp.groupby([var])['ID_code'].transform('count')/size\n",
    "        mode = tmp[var].mode()\n",
    "        mean = tmp[var].mean()\n",
    "        std = tmp[var].std()\n",
    "        #tmp[var+'_dis'] = tmp[var].apply(lambda x:abs(x-mode)/std)\n",
    "        #tmp[var+'_count'] = tmp[var+'_dis']/tmp[var+'_count']\n",
    "        df[var+'_count'] = tmp.iloc[:df.shape[0]][var+'_count']\n",
    "        #df[var+'_dis'] = tmp.iloc[:df.shape[0]][var+'_dis']\n",
    "        \n",
    "        add_0[var+'_count'] = tmp.iloc[df.shape[0]:df.shape[0]+add_0.shape[0]][var+'_count']\n",
    "        #add_0[var+'_dis'] = tmp.iloc[df.shape[0]:df.shape[0]+add_0.shape[0]][var+'_dis']\n",
    "        \n",
    "        add_1[var+'_count'] = tmp.iloc[df.shape[0]+add_0.shape[0]:][var+'_count']\n",
    "        #add_1[var+'_dis'] = tmp.iloc[df.shape[0]+add_0.shape[0]:][var+'_dis']\n",
    "        \n",
    "        \n",
    "    return df, add_0, add_1\n",
    "\n",
    "\n",
    "feature = 'var_12'\n",
    "\n",
    "train_new, test_true, test_synthetic = transform_fre_dis(train_new, test_true, test_synthetic, [feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, feature+'_dis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, feature+'_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_new[['var_12', 'var_12_count', 'var_12_dis', 'target']]\n",
    "tmp = tmp.groupby('var_12')[['var_12_count', 'var_12_dis', 'target']].mean().sort_values(by='var_12_count', ascending=False)\n",
    "tmp.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis_hist(train_new, 'var_12_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_(df, add_0, add_1, var):\n",
    "    \n",
    "    total_cols = [var]\n",
    "    total_cols.append('ID_code')\n",
    "    tmp = pd.concat([df[total_cols]], axis=0)\n",
    "    \n",
    "    tmp['random_{}'.format(var)] = np.random.normal(tmp[var].mean(), tmp[var].std(), tmp.shape[0]).round(4)\n",
    "    var_counts = pd.DataFrame(tmp.groupby(var)['ID_code'].count()).reset_index()\n",
    "    var_counts_random = pd.DataFrame(tmp.groupby('random_{}'.format(var))['ID_code'].count()).reset_index()\n",
    "    merged_counts = pd.merge(var_counts, var_counts_random, left_on=var, right_on='random_{}'.format(var))\n",
    "    merged_counts['diff'] = merged_counts['ID_code_x'] - merged_counts['ID_code_y']\n",
    "    tmp['{}_diff_normal_dist'.format(var)] = tmp.merge(merged_counts[[var,'diff']], how='left')['diff']\n",
    "    df['{}_diff_normal_dist'.format(var)] = tmp.iloc[:df.shape[0]]['{}_diff_normal_dist'.format(var)]/tmp.shape[0]\n",
    "    #df = df.drop('random_{}'.format(var), axis=1)\n",
    "    return df\n",
    "\n",
    "train_new = transform_(train_new, test_true, test_synthetic, 'var_12')\n",
    "test_true = transform_(test_true, train_new, test_synthetic, 'var_12')\n",
    "test_synthetic = transform_(test_synthetic, train_new, test_true, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_all(train_new, test_true, test_synthetic, 'test_var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'test_var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_all(train_new, test_true, test_synthetic, 'new_var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_train_test_true(train_new, test_true, 'new_var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_train_test_syn(train_new, test_synthetic, 'new_var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'new_var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_target(train_new, 'fe_var_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_target(df, feature):\n",
    "    negData = df.loc[df['target'] == 0][feature]\n",
    "    posData = df.loc[df['target'] == 1][feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([negData, posData], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"target 0\", \"target 1\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_target_test(df, test, feature):\n",
    "    negData = df.loc[df['target'] == 0][feature]\n",
    "    posData = df.loc[df['target'] == 1][feature]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    outs1, outs2, outs3 = ax.hist([test[feature], negData, posData], \n",
    "                                  bins=30, \n",
    "                                  density = True, \n",
    "                                  histtype='step', \n",
    "                                  label=(\"test\", \"target 0\", \"target 1\"),\n",
    "                                  linewidth=3)\n",
    "    ax.set_xticks(outs2)\n",
    "    ax.xaxis.grid(True)\n",
    "    handles, labels=ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_train_test(train_new, test_true, 'var_81')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(train_new, 'var_81')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_count(train_new, feature):\n",
    "    \n",
    "    \n",
    "    Data = train_new[feature].value_counts() \n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 1, figsize=(20,5))\n",
    "\n",
    "    fig.suptitle(feature)\n",
    "    plt.bar(Data.index, Data.values, align='center')\n",
    "\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_count(train_new, 'var_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_new['var_3'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dis(name):\n",
    "    xx = plt.xlim(11, 16)\n",
    "    sns.distplot(train0[name], label = 't=0')\n",
    "    sns.distplot(train1[name], label = 't=1')\n",
    "    plt.title(name)\n",
    "    plt.legend()\n",
    "    plt.xlim(xx)\n",
    "    plt.xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis('var_126')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis('var_126_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = get_pdf(train_new,'var_126_map')\n",
    "plt.plot(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(train_new[train_new['target']==1]['var_126']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new['var_126'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc='Progress')\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import gc\n",
    "\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "private_lb = pd.read_csv(\"../input/Private_LB.csv\")\n",
    "public_lb = pd.read_csv(\"../input/Public_LB.csv\")\n",
    "synthetic = pd.read_csv(\"../input/synthetic_samples_indexes.csv\")\n",
    "\n",
    "private_lb = private_lb.rename(index=str, columns={\"Private_LB\": \"index\"})\n",
    "public_lb = public_lb.rename(index=str, columns={\"Public_LB\": \"index\"})\n",
    "synthetic = synthetic.rename(index=str, columns={\"synthetic_samples_indexes\": \"index\"})\n",
    "\n",
    "true = public_lb.append(private_lb, ignore_index=True)\n",
    "\n",
    "test_true = test.iloc[true[\"index\"], :]\n",
    "test_synthetic = test.iloc[synthetic[\"index\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cols = [c for c in df_train.columns if c not in ['target']]\n",
    "tmp = pd.concat([df_train[total_cols], test_true[total_cols]], axis=0)\n",
    "x = df_train['var_0'].value_counts()\n",
    "y = test_true['var_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x /= df_train.shape[0]\n",
    "y /= test_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.DataFrame(x.index, columns=['id'])\n",
    "m['mean'] = m['id'].apply(lambda x:df_train[df_train['var_0']==x]['target'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.sort_values(by='mean', ascending=False)\n",
    "m.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[13.9072]*df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tmp['var_0'].value_counts()\n",
    "#w = w.where(w<2, 0)\n",
    "w /= tmp.shape[0]\n",
    "#for idx in w.index:\n",
    "    #w[idx] = w[idx]/(abs(idx-w.index[0])+1e-8)\n",
    "\n",
    "w = w.sort_values(ascending=False)\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "i = 0\n",
    "while (len(arr)<=100):\n",
    "    idx = w.index[i]\n",
    "    if(idx in x.index):\n",
    "        #print(df_train[df_train['var_12']==idx]['target'].mean())\n",
    "        arr.append(df_train[df_train['var_0']==idx]['target'].mean())\n",
    "    i += 1\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.copy()\n",
    "for idx in z.index:\n",
    "    if(idx in y.index):\n",
    "        z[idx] = (1-np.log(y[idx]-z[idx]+1e-8))*(z[idx]+y[idx])\n",
    "    else:\n",
    "        z[idx] = (1-np.log(z[idx]+1e-8))*z[idx]\n",
    "z = z.sort_values(ascending=False)\n",
    "z.head(20)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(20):\n",
    "    idx = z.index[i]\n",
    "    print(df_train[df_train['var_0']==idx]['target'].mean())\n",
    "    #arr.append(df_train[df_train['var_0']==idx]['target'].mean())\n",
    "\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(20):\n",
    "    idx = x.index[len(x.index)-i-1]\n",
    "    #print(df_train[df_train['var_126']==idx]['target'].mean())\n",
    "    arr.append(df_train[df_train['var_0']==idx]['target'].mean())\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "while (len(arr)<=20):\n",
    "    idx = y.index[len(y.index)-i-1]\n",
    "    if(idx in x.index):\n",
    "        #print(df_train[df_train['var_126']==idx]['target'].mean())\n",
    "        arr.append(df_train[df_train['var_0']==idx]['target'].mean())\n",
    "    i += 1\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in x.index:\n",
    "    if (idx>13.5538)and(idx<13.5553):\n",
    "        print(idx, x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[13.9842])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train['var_12']==14.1713]['target'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train['var_12']==13.5550]['target'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train['var_12']==13.5545]['target'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train['var_12']==14.0810]['target'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train['var_12']==14.0616]['target'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_true['var_126'].value_counts().index:\n",
    "    if i not in train_new['var_126'].value_counts().index:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_12 = train_new.groupby(['var_12'])['target'].agg(['count','mean']).sort_values('count', ascending=False)\n",
    "print(new_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis('var_108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dis('noise_var_108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_108 = train_new.groupby(['var_108'])['target'].agg(['count','mean']).sort_values('count', ascending=False)\n",
    "print(new_108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3env",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
